<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Search | xiaobaoqiu Blog]]></title>
  <link href="http://xiaobaoqiu.github.io/blog/categories/search/atom.xml" rel="self"/>
  <link href="http://xiaobaoqiu.github.io/"/>
  <updated>2015-08-22T13:29:23+08:00</updated>
  <id>http://xiaobaoqiu.github.io/</id>
  <author>
    <name><![CDATA[xiaobaoqiu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[分词]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/07/17/fen-ci/"/>
    <updated>2015-07-17T01:24:30+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/07/17/fen-ci</id>
    <content type="html"><![CDATA[<p>最近有需求需要使用crate搜索时候的分词功能,正好研究一下搜索中分词相关的基础知识
.</p>

<h1>1.什么是分词</h1>

<h1>2.为什么要分词</h1>

<h1>3.怎么做分词</h1>

<p>参考：<a href="http://my.oschina.net/apdplat/blog/412921">http://my.oschina.net/apdplat/blog/412921</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crate服务load飙高]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/07/16/cratefu-wu-loadbiao-gao/"/>
    <updated>2015-07-16T05:02:20+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/07/16/cratefu-wu-loadbiao-gao</id>
    <content type="html"><![CDATA[<p>前段时间搜索处理个P3的故障,原因是用户输入超级长的搜索字段,导致crate服务器load飙高,进而对外服务失败.</p>

<p>持续时间约10分钟.但是对我而言,最大的问题是这10分钟内,对crate服务器我什么都做不了.经过这次问题,准备好好看看crate以及背后ES的源码.</p>

<p>虽然解决方案是限制用户输入(这一点和google以及百度做法是一样的,百度的查询限制在38个汉字以内).</p>

<h1>1.like查询</h1>

<p>有问题的字段是name字段,使用crate的简单的like查询.根据官方文档,crate的like查询支持两种通配符:</p>

<pre><code>% : 0个或者多个字符
_ : 单个字符
</code></pre>

<p>需要注意的注意,使用like查询可能导致慢查询.特别是当使用前置通配符开头的like查询.因为这种情况下crate需要去迭代所有行,而不能使用索引.
如果向获取更好的性能,可以考虑使用全文索引.</p>

<p>like参考:<a href="https://crate.io/docs/en/latest/sql/queries.html#like">https://crate.io/docs/en/latest/sql/queries.html#like</a></p>

<p>全文索引参考: <a href="https://crate.io/docs/en/latest/sql/fulltext.html">https://crate.io/docs/en/latest/sql/fulltext.html</a> <a href="https://crate.io/docs/en/latest/sql/ddl.html#fulltext-indices">https://crate.io/docs/en/latest/sql/ddl.html#fulltext-indices</a></p>

<h1>2.crate符取异常日志</h1>

<p>这里贴一下当时crate服务器的异常:
<code>
org.elasticsearch.index.query.QueryParsingException: [merchant_sea] Failed to parse
        at org.elasticsearch.index.query.IndexQueryParserService.parseQuery(IndexQueryParserService.java:370)
        at org.elasticsearch.action.count.TransportCountAction.shardOperation(TransportCountAction.java:187)
        at org.elasticsearch.action.count.CrateTransportCountAction.shardOperation(CrateTransportCountAction.java:119)
        at org.elasticsearch.action.count.CrateTransportCountAction.shardOperation(CrateTransportCountAction.java:49)
        at org.elasticsearch.action.support.broadcast.TransportBroadcastOperationAction$AsyncBroadcastAction$1.run(TransportBroadcastOperationAction.java:171)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.lucene.util.automaton.TooComplexToDeterminizeException: Determinizing automaton would result in more than 10000 states.
        at org.apache.lucene.util.automaton.Operations.determinize(Operations.java:743)
        at org.apache.lucene.util.automaton.RunAutomaton.&lt;init&gt;(RunAutomaton.java:138)
        at org.apache.lucene.util.automaton.ByteRunAutomaton.&lt;init&gt;(ByteRunAutomaton.java:32)
        at org.apache.lucene.util.automaton.CompiledAutomaton.&lt;init&gt;(CompiledAutomaton.java:203)
        at org.apache.lucene.search.AutomatonQuery.&lt;init&gt;(AutomatonQuery.java:84)
        at org.apache.lucene.search.AutomatonQuery.&lt;init&gt;(AutomatonQuery.java:65)
        at org.apache.lucene.search.WildcardQuery.&lt;init&gt;(WildcardQuery.java:57)
        at org.elasticsearch.index.query.WildcardQueryParser.parse(WildcardQueryParser.java:106)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.IndexQueryParserService.innerParse(IndexQueryParserService.java:382)
        at org.elasticsearch.index.query.IndexQueryParserService.parse(IndexQueryParserService.java:281)
        at org.elasticsearch.index.query.IndexQueryParserService.parse(IndexQueryParserService.java:276)
        at org.elasticsearch.index.query.IndexQueryParserService.parseQuery(IndexQueryParserService.java:354)
        ... 7 more
</code></p>

<h1>3.背后的原理</h1>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch配置解析]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/05/21/elasticsearchpei-zhi-jie-xi/"/>
    <updated>2015-05-21T04:31:05+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/05/21/elasticsearchpei-zhi-jie-xi</id>
    <content type="html"><![CDATA[<p>可以使用正则grep出各个配置项:
<code>
grep '^#\w' elasticsearch.yml
</code></p>

<p>解析Elasticsearch的配置文件elasticsearch.yml中各个关键参数的意义:</p>

<pre><code>################################### Cluster ###################################
elasticsearch的config文件夹里面有两个配置文件：elasticsearch.yml和logging.yml，第一个是es的基本配置文件，第二个是日志配置文件，es也是使用log4j来记录日志的，所以logging.yml里的设置按普通log4j配置文件来设置就行了。下面主要讲解下elasticsearch.yml这个文件中可配置的东西。

cluster.name: elasticsearch
配置es的集群名称，默认是elasticsearch，es会自动发现在同一网段下的es，如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。

node.name: "Franz Kafka"
节点名，默认随机指定一个name列表中名字，该列表在es的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字。

node.master: true
指定该节点是否有资格被选举成为node，默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master。

node.data: true
指定该节点是否存储索引数据，默认为true。

index.number_of_shards: 5
设置默认索引分片个数，默认为5片。

index.number_of_replicas: 1
设置默认索引副本个数，默认为1个副本。

path.conf: /path/to/conf
设置配置文件的存储路径，默认是es根目录下的config文件夹。

path.data: /path/to/data
设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开，例：
path.data: /path/to/data1,/path/to/data2

path.work: /path/to/work
设置临时文件的存储路径，默认是es根目录下的work文件夹。

path.logs: /path/to/logs
设置日志文件的存储路径，默认是es根目录下的logs文件夹

path.plugins: /path/to/plugins
设置插件的存放路径，默认是es根目录下的plugins文件夹

bootstrap.mlockall: true
设置为true来锁住内存。因为当jvm开始swapping时es的效率会降低，所以要保证它不swap，可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过`ulimit -l unlimited`命令。设置ES_HEAP_SIZE表示ES_MIN_MEM和ES_MAX_MEM相同且为ES_HEAP_SIZE的值.

network.bind_host: 192.168.0.1
设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0。

network.publish_host: 192.168.0.1
设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。

network.host: 192.168.0.1
这个参数是用来同时设置bind_host和publish_host上面两个参数。

transport.tcp.port: 9300
设置节点间交互的tcp端口，默认是9300。

transport.tcp.compress: true
设置是否压缩tcp传输时的数据，默认为false，不压缩。

http.port: 9200
设置对外服务的http端口，默认为9200。

http.max_content_length: 100mb
设置内容的最大容量，默认100mb

http.enabled: false
是否使用http协议对外提供服务，默认为true，开启。

gateway.type: local
gateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS，和amazon的s3服务器，其它文件系统的设置方法下次再详细说。

gateway.recover_after_nodes: 1
设置集群中N个节点启动时进行数据恢复，默认为1。

gateway.recover_after_time: 5m
设置初始化数据恢复进程的超时时间，默认是5分钟。

gateway.expected_nodes: 2
设置这个集群中节点的数量，默认为2.一旦一旦这N个节点启动(并且数字和recover_after_nodes相同),就会立即开始数据恢复而不用等待gateway.recover_after_time时间之后再开始.

cluster.routing.allocation.node_initial_primaries_recoveries: 4
初始化数据恢复时，并发恢复线程的个数，默认为4。

cluster.routing.allocation.node_concurrent_recoveries: 2
添加删除节点或负载均衡时并发恢复线程的个数，默认为4。

indices.recovery.max_size_per_sec: 0
设置数据恢复时限制的带宽，如入100mb，默认为0，即无限制。

indices.recovery.concurrent_streams: 5
设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5。

discovery.zen.minimum_master_nodes: 1
设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值(2-4).

discovery.zen.ping.timeout: 3s
设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。

discovery.zen.ping.multicast.enabled: false
设置是否打开多播发现节点，默认是true。使用单播发现节点策略(Unicast discovery)允许显示的控制使用哪个节点去发现集群.

discovery.zen.ping.unicast.hosts: ["host1", "host2:port", "host3[portX-portY]"]
设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。

下面是一些查询时的慢日志参数设置,默认日志级别为TRACE.
超过10秒的查询打印warn日志,超过5秒的查询打印info日志,超过2秒的查询打印debug日志,超过0.5秒的查询打印trace日志
index.search.slowlog.level: TRACE
index.search.slowlog.threshold.query.warn: 10s
index.search.slowlog.threshold.query.info: 5s
index.search.slowlog.threshold.query.debug: 2s
index.search.slowlog.threshold.query.trace: 500ms

index.search.slowlog.threshold.fetch.warn: 1s
index.search.slowlog.threshold.fetch.info: 800ms
index.search.slowlog.threshold.fetch.debug:500ms
index.search.slowlog.threshold.fetch.trace: 200ms

超过10秒的查检索引打印warn日志,超过5秒的查检索引打印info日志,超过2秒的查检索引打印debug日志,超过0.5秒的查检索引打印trace日志
index.indexing.slowlog.threshold.index.warn: 10s
index.indexing.slowlog.threshold.index.info: 5s
index.indexing.slowlog.threshold.index.debug: 2s
index.indexing.slowlog.threshold.index.trace: 500ms

下面是GC日志相关的配置,young GC超过1000ms打印warn日志,超过700ms打印info日志,超过400ms打印的debug日志
monitor.jvm.gc.young.warn: 1000ms
monitor.jvm.gc.young.info: 700ms
monitor.jvm.gc.young.debug: 400ms

full GC超过10s打印warn日志,超过5s打印info日志,超过2s打印的debug日志
monitor.jvm.gc.old.warn: 10s
monitor.jvm.gc.old.info: 5s
monitor.jvm.gc.old.debug: 2s
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/05/20/elasticsearch/"/>
    <updated>2015-05-20T22:14:33+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/05/20/elasticsearch</id>
    <content type="html"><![CDATA[<h1>1.简介</h1>

<p>Elasticsearch 是一个建立在全文搜索引擎 Apache Lucene&trade; 基础上的分布式的，高可用的，基于json格式的数据构建索引，准实时查询的搜索引擎。Lucene 是当今最先进最高效的全功能开源搜索引擎框架,但是Lucene使用非常复杂。</p>

<p>Elasticsearch使用 Lucene 作为内部引擎，但是在你使用它做全文搜索时，只需要使用统一开发好的API即可，而并不需要了解其背后复杂的 Lucene 的运行原理。</p>

<p>Elasticsearch是一种准实时搜索，其实是可以做到实时的，因为lucene是可以做到实时的，但是这样做，要么是牺牲索引的效率（每次都索引之后刷新），要么就是牺牲查询的效率（每次查询之前都进行刷新），所以
采取一种折中的方案，每隔n秒自动刷新，这样你创建索引之后，最多在ns之内肯定能查到，这就是所谓的准实时(near real-time)查询，缺省是刷新间隔时间是1秒，可以通过index.refresh_interval参数修改间隔.</p>

<p>刷新是为了让文档可以搜索到，但是不保证这些数据被写入disk进入一个永久的存储状态，数据会被先被写入一个事务日志，然后在适当的时候持久化到磁盘中.</p>

<p>官网:<a href="https://www.elastic.co/products/elasticsearch">https://www.elastic.co/products/elasticsearch</a></p>

<p>文档:<a href="https://www.elastic.co/guide/index.html">https://www.elastic.co/guide/index.html</a></p>

<p>github地址:<a href="https://github.com/elastic/elasticsearch">https://github.com/elastic/elasticsearch</a></p>

<p>博客地址:<a href="https://www.elastic.co/blog">https://www.elastic.co/blog</a></p>

<p>其优点很吸引人:</p>

<pre><code>1.分布式,可扩展,高科用(Distributed, scalable, and highly available);
2.提供实时搜索和分析(Real-time search and analytics capabilities);
3.复杂的RESTful API接口(Sophisticated RESTful API);
</code></pre>

<p>其特征如下:</p>

<pre><code>1.Real-Time Data
2.Real-Time Analytics
3.Distributed
最开始规模可能很小,elasticsearch很方便的支持横向扩展,通过简单的在集群中增加节点就可以
4.High Availability
Elasticsearch集群是弹性的,它可以自动的感知新增的或者失效的节点,自动做数据的分发和均衡,保证数据客房问并且是安全的.
5.Multitenancy
集群可能包含多个索引(index),它们可以独立的提供查询服务,也可以组合在一起对外提供查询服务.
6.Full-Text Search
支持多种开发语言
7.Document-Oriented
将真实世界的复杂对象结构化乘JSON文档.所有字段默认都建立索引,所有的索引都可以单独提供查询.并且瞬间(breathtaking speed)返回复杂结果.
8.Schema-Free
对一个JSON文档建立索引,就会自动识别数据的结构和类型,创建所有并对外提供搜索服务.同时也可以自定义数据如何建立索引.
9.Developer-Friendly, RESTful API
Elasticsearch是API驱动的.基本所有的操作都可以通过一个简单的使用JSON格式数据的HTTP上的RESTful API.提供了很多种语言的Client.
10.Per-Operation Persistence
Elasticsearch将数据安全放在第一位.任何文档的变更都会记录在集群中多个节点上的事物日志,以此来将数据丢失几率降低到最小.
11.Apache 2 Open Source License
12.Build on top of Apache Lucene
Elasticsearch以Lucene为基础提供其优秀的分布式搜索和分析能力.
13.Conflict Management
</code></pre>

<h1>2.安装</h1>

<h3>2.1 elasticsearch安装</h3>

<p>安装很简单:</p>

<pre><code>1.下载并解压
下载地址:https://www.elastic.co/downloads/elasticsearch
这里下载是1.5.2版本,解压之后可以创建软链es:

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>xiaobaoqiu@xiaobaoqiu:~/elasticsearch$ ln -s elasticsearch-1.5.2 es</span></code></pre></td></tr></table></div></figure>

目录下主要三个文件夹:

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>xiaobaoqiu@xiaobaoqiu:~/elasticsearch/es$ ll
</span><span class='line'>总用量 48
</span><span class='line'>drwxr-xr-x 5 xiaobaoqiu xiaobaoqiu  4096  4月 27 09:22 ./
</span><span class='line'>drwxr-xr-x 3 xiaobaoqiu xiaobaoqiu  4096  5月 20 14:40 ../
</span><span class='line'>drwxr-xr-x 2 xiaobaoqiu xiaobaoqiu  4096  4月 27 09:22 bin/
</span><span class='line'>drwxr-xr-x 2 xiaobaoqiu xiaobaoqiu  4096  5月 20 14:42 config/
</span><span class='line'>drwxr-xr-x 3 xiaobaoqiu xiaobaoqiu  4096  4月 27 09:22 lib/
</span><span class='line'>-rw-rw-r-- 1 xiaobaoqiu xiaobaoqiu 11358  4月 27 07:05 LICENSE.txt
</span><span class='line'>-rw-rw-r-- 1 xiaobaoqiu xiaobaoqiu   150  4月 27 07:05 NOTICE.txt
</span><span class='line'>-rw-rw-r-- 1 xiaobaoqiu xiaobaoqiu  8499  4月 27 09:03 README.textile</span></code></pre></td></tr></table></div></figure>
其中bin包含一些启动脚本(包括windows下的bat脚本和linux下的shell脚本),config主要是配置文件,lib包括es依赖的jar,在里面就可以看到熟悉的Lucene,查询,高亮等依赖的jar包.

启动elasticsearch之后会产生log目录,用于记录elasticsearch系统的一些中心日志信息:

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-rw-r--r-- 1    0  5月 20 15:05 elasticsearch_index_indexing_slowlog.log
</span><span class='line'>-rw-r--r-- 1    0  5月 20 15:05 elasticsearch_index_search_slowlog.log
</span><span class='line'>-rw-r--r-- 1 1254  5月 20 15:06 elasticsearch.log</span></code></pre></td></tr></table></div></figure>
其中elasticsearch.log是系统日志,记录什么类型的日志,日志的命名及日志文件的滚动(Rolling)策略等由config目录下的logging.yml配置文件决定.

启动elasticsearch之后会产生data目录,用于
elasticSearch的数据存放位置

2.启动
直接启动bin目录下的elasticsearch的shell:

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>xiaobaoqiu@xiaobaoqiu:~/elasticsearch/es/bin$ ./elasticsearch -d</span></code></pre></td></tr></table></div></figure>

3.验证
直接本机浏览器访问:http://localhost:9200/

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>status: 200,
</span><span class='line'>name: "Agon",
</span><span class='line'>cluster_name: "elasticsearch",
</span><span class='line'>version: {
</span><span class='line'>    number: "1.5.2",
</span><span class='line'>    build_hash: "62ff9868b4c8a0c45860bebb259e21980778ab1c",
</span><span class='line'>    build_timestamp: "2015-04-27T09:21:06Z",
</span><span class='line'>    build_snapshot: false,
</span><span class='line'>    lucene_version: "4.10.4"
</span><span class='line'>},
</span><span class='line'>tagline: "You Know, for Search"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>
这说明Elasticsearch集群已经上线运行了，这时我们就可以进行各种实验了.
</code></pre>

<h3>2.2 集群管理工具插件</h3>

<p>elasticsearch-head是一个elasticsearch的集群管理工具，它是完全由html5编写的独立网页程序，其他它可以更好的获得各个切片和节点的信息.</p>

<p>该工具的git地址是： <a href="https://github.com/Aconex/elasticsearch-head">https://github.com/Aconex/elasticsearch-head</a></p>

<p>安装该插件:</p>

<pre><code>xiaobaoqiu@xiaobaoqiu:~/elasticsearch$ ./es/bin/plugin -install mobz/elasticsearch-head
-&gt; Installing mobz/elasticsearch-head...
...//省略若干
</code></pre>

<p>然后就可以访问(可以使用具体节点的IP):
<a href="http://localhost:9200/_plugin/head/">http://localhost:9200/_plugin/head/</a></p>

<p>图形化界面如下,包括集群的健康状况等信息:</p>

<p><img src="/images/Elasticsearch/elasticsearch_plugin_head.png"></p>

<h3>2.3 集群监控工具插件</h3>

<p>bigdesk是elasticsearch的一个集群监控工具，可以通过它来查看es集群的各种状态，如：cpu、内存使用情况，索引数据、搜索情况，http连接数等。</p>

<p>项目git地址： <a href="https://github.com/lukas-vlcek/bigdesk">https://github.com/lukas-vlcek/bigdesk</a></p>

<p>安装该插件:</p>

<pre><code>xiaobaoqiu@xiaobaoqiu:~/elasticsearch$ ./es/bin/plugin -install lukas-vlcek/bigdesk
-&gt; Installing lukas-vlcek/bigdesk...
...//省略若干
</code></pre>

<p>然后就可以访问(可以使用具体节点的IP):
<a href="http://localhost:9200/_plugin/bigdesk/">http://localhost:9200/_plugin/bigdesk/</a></p>

<p>图形化界面如下,包括JVM,Thread Pools,OS,Process,HTTP &amp; Transport,Indices和File system等监控图:</p>

<p><img src="/images/Elasticsearch/elasticsearch_plugin_bigdesk.png"></p>

<h3>2.4 安装Marvel</h3>

<p>Marvel是Elasticsearch的管理和监控工具，是一个商业版本的插件,在开发环境下免费使用。它包含了一个叫做Sense的交互式控制台，使用户方便的通过浏览器直接与Elasticsearch进行交互。</p>

<p>运行以下命令来下载和安装Marvel:</p>

<pre><code>xiaobaoqiu@xiaobaoqiu:~/elasticsearch$ ./es/bin/plugin -i elasticsearch/marvel/latest
-&gt; Installing elasticsearch/marvel/latest...
...//省略若干
</code></pre>

<p>Marvel包括一系列酷炫的监控,还有一个Sense的交互式控制台:</p>

<p><img src="/images/Elasticsearch/elasticsearch_plugin_marvel.png"></p>

<p><img src="/images/Elasticsearch/elasticsearch_plugin_marvel_sense.png"></p>

<p>你可能想要禁用监控，你可以通过以下命令关闭Marvel：</p>

<pre><code>echo 'marvel.agent.enabled: false' &gt;&gt; ./config/elasticsearch.yml
</code></pre>

<h1>3.基本概念</h1>

<h3>3.1 集群和节点</h3>

<p>节点是Elasticsearch运行的实例。集群是一组有着同样cluster.name的节点，它们协同工作，互相分享数据，提供了故障转移和扩展的功能。当然一个节点也可以是一个集群。ES集群有自动发现的机制，只要几个节点用的是一个clustername，并且在一个局域网内，那么这些节点就可以自动的发现对方，并组成一个集群.</p>

<p>我们上面的运行就是一个单节点的集群.节点的cluster.name在配置文件elasticsearch.yml中配置,默认就叫elasticsearch:</p>

<pre><code>cluster.name: elasticsearch
</code></pre>

<p>ES的集群是一个去中心化的集群，每一个节点都可以被选举为主节点，如果主节点挂了，集群就会选举出新的主节点。</p>

<p>主节点的作用主要是管理集群，例如感知集群节点的增加和减少，平衡数据分配等.</p>

<p>ES集群对外是透明的，各个节点之间协同工作，分享数据，我们不管访问的是哪一个节点，这个节点都知道数据存在于哪个节点上，然后转发请求到数据所在的节点上，并且负责收集各节点返回的数据，最后一起返回给客户端.</p>

<h3>3.2 分片(shard)</h3>

<p>一个索引会被分割为多个片段存储，这样可以充分使用节点的吞吐率</p>

<h3>3.2 索引(index)</h3>

<p>相当于数据库</p>

<h3>3.3 类型(type)</h3>

<p>相当于数据库中的表</p>

<h3>3.4 文档(doc)</h3>

<p>相当于数据库中的一条记录，json串</p>

<h3>3.5 字段(Field)</h3>

<p>相当路数据库中的列。</p>

<p>参考:
<a href="http://es.xiaoleilu.com/">http://es.xiaoleilu.com/</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crate Jdbc查询死循环bug]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/05/20/crate-jdbccha-xun-si-xun-huan-bug/"/>
    <updated>2015-05-20T05:41:17+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/05/20/crate-jdbccha-xun-si-xun-huan-bug</id>
    <content type="html"><![CDATA[<p>历经一个月的项目,使用Crate提升搜索速度终于要上线.先交代一下背景,我们使用的crate相关的依赖的版本:</p>

<pre><code>1.crate-client  0.47.8
2.crate-jdbc    1.5.1
</code></pre>

<p>发布之后,验证阶段一切正常,等把流量入口打开,一段时间之后,猛然发现crate的一个查询服务所在的机器load飙到20往上,机器是4核CPU,4G内存的虚拟机.</p>

<p>top -H发现有大量的tomcat线程(10+),每个线程占用的CPU都达到20%,并且这种线程有增多的趋势.</p>

<p>vmstat命令发现r数字特别高,即正在等待CPU的线程非常多.</p>

<p>jstack的结果发现runnable的线程多达300多.</p>

<p>看现象,感觉问题是线程池分配没有回收,但是定位不到问题在哪.</p>

<p>最终定位的问题是在特定场景下存在死循环,并且直接才crate服务器执行相同的查询逻辑正常返回,因此基本定位在crate-jdbc中.</p>

<h1>1.死循环场景</h1>

<pre><code>1.crate中数据为空,这是很从crate中查询数据;
2.crate中存在满足查询条件数据,我们分页查询,假设总数据量为10页,我们因为代码问题,直接查询第11页的内容(实际上肯定不存在);
</code></pre>

<h1>2.原因</h1>

<p>原因是这个版本crate-jdbc和mybatis一起存在死循环,如下,我们对crate的查询首先经过mybatis,从</p>

<pre><code>1.MapperProxy.invoke
2.MapperMethod.execute
3.SqlSessionTemplate.selectList, SqlSessionTemplate.invoke
4.DefaultSqlSession.selectList
5.BaseExecutor.query, BaseExecutor.queryFromDatabase
6.ReuseExecutor.doQuery
7.RoutingStatementHandler.query
8.PreparedStatementHandler.query
9.CratePreparedStatement.execute()
10.DefaultResultSetHandler.handleResultSets, DefaultResultSetHandler.getFirstResultSet
</code></pre>

<p>问题的代码就在DefaultResultSetHandler.getFirstResultSet中:
<code>
private ResultSetWrapper getFirstResultSet(Statement stmt) throws SQLException {
    ResultSet rs = stmt.getResultSet();
    while (rs == null) {
        // move forward to get the first resultset in case the driver
        // doesn't return the resultset as the first result (HSQLDB 2.1)
        if (stmt.getMoreResults()) {
            rs = stmt.getResultSet();
        } else {
            if (stmt.getUpdateCount() == -1) {
                // no more results. Must be no resultset
                break;
            }
        }
    }
    return rs != null ? new ResultSetWrapper(rs, configuration) : null;
}
</code>
其中stmt为CratePreparedStatement,其getMoreResults()实现:
<code>
@Override
public boolean getMoreResults() throws SQLException {
    return false;
}
</code>
因此逻辑进入到else中,stmt.getUpdateCount()的实现:
<code>
@Override
public int getUpdateCount() throws SQLException {
    checkClosed();  //check connection是否被关闭
    if (resultSet == null &amp;&amp; sqlResponse != null) {
        return (int) sqlResponse.rowCount();
    }
    return -1;
}
</code>
其中CratePreparedStatement的resultSet为null,并且sqlResponse不为空,sqlResponse的rowCount为0,因此getUpdateCount()返回值为0.因此getFirstResultSet中继续在while循环中,无法跳出.</p>

<p><img src="/images/crate/crate_jdbc_bug_code.png"></p>

<h1>3.绕过</h1>

<p>归结起来产生问题的很简单,就是查询的结果集为空的时候,就会产生死循环,针对两种死循环场景,我们都可以绕过:</p>

<pre><code>1.查询之前,先执行count查询,当count为0,即crate中没有满足我们查询条件的数据,则直接返回空数据集;
2.分页查询的时候,先执行count查询,当分页的offset大于等于count,则值额节返回空数据集;
</code></pre>
]]></content>
  </entry>
  
</feed>
