<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Search | xiaobaoqiu Blog]]></title>
  <link href="http://xiaobaoqiu.github.io/blog/categories/search/atom.xml" rel="self"/>
  <link href="http://xiaobaoqiu.github.io/"/>
  <updated>2015-09-09T22:16:53+08:00</updated>
  <id>http://xiaobaoqiu.github.io/</id>
  <author>
    <name><![CDATA[xiaobaoqiu]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Lucene入门]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/09/03/luceneru-men/"/>
    <updated>2015-09-03T14:13:54+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/09/03/luceneru-men</id>
    <content type="html"><![CDATA[<p>Crate再项目中扮演越来越重要的角色.但是很多时候我对Crate,包括其下层的ElasticSearch以及Lucene都是一知半解,甚至可以说是完全不懂.因为没看过源代码.所以这段时间会集中学习一下Lucene和ElasticSearch的源码.</p>

<p>从Lucene开始.会包含以下内容:</p>

<pre><code>1.Lucene简介;
2.Lunece整体架构;
3.Lucene的存储;
4.Lucene的搜索;
5.Lucene其他功能,如高亮等;
</code></pre>

<p>这里从Lucene简介开始.第一次使用Lucene已经是两年前入职的时候,写了个简单的爬虫,抓取999网的疾病信息并提供一个简单的搜索入口.这里主要弄懂以下几个问题:</p>

<pre><code>1.信息检索
2.Lucene是什么;
3.Lucene建立索引的大致过程;
4.Lucene搜索的大致过程;
</code></pre>

<p>Lucene官网: <a href="http://lucene.apache.org/">http://lucene.apache.org/</a></p>

<p>在Lucene基础上衍生出很多搜索框架,下面是这些框架的对比:<a href="http://stackoverflow.com/questions/2271600/elasticsearch-sphinx-lucene-solr-xapian-which-fits-for-which-usage">http://stackoverflow.com/questions/2271600/elasticsearch-sphinx-lucene-solr-xapian-which-fits-for-which-usage</a></p>

<h2>1.信息检索</h2>

<p>信息检索简单讲就是从一堆数据中找到你需要的数据,数据的来源可能是文本或者网络,甚至别人说的话或者声波等等.比如:</p>

<ul>
<li>从一个Excel表格中找到你的名字;</li>
<li>从学生成绩标表中找到不及格的学生;</li>
<li>从图书馆里面找Java编程相关的书籍;</li>
<li>从网络搜索Lucene相关知识;</li>
<li>老师点名时候喊到;</li>
</ul>


<p>人类信息检索也是一个不断发展的过程,下面这个例子简单的诠释了信息检索的改善过程:</p>

<ol>
<li>一个书生想从书屋(假设1000本书)里找一本书他能做的就是,从第一本书开始一本一本的往后找,直到找到他要的那本书.如果很不幸,书屋里面每这本书,那么他就必须翻遍所以的书,很可能他找一遍需要10个小时;</li>
<li>经历过几次这样痛苦的找书经历之后,书生开始想招了,将书分类(假设10个分类),文学类在第一个书架子,史学类再第二个书架子&hellip;从此以后,他找书比以前方便多了.找一本书最多只需要翻一个架子,时间缩短到1个小时;但是带来的成本是:必须将书正确的放在其正确的架子上;</li>
<li>每次翻遍一个架子,书生觉得还是比较麻烦,于是他给每本书加了一个编号,将书按照编号排列好,并将所以的书名和编号的对应关系记录到一个单独的册子上.下次他找书只需要在册子上找就可以了(只需要看册子上的1000个书名),找到书名对应的编号,然后就能快速的找到书,时间只需要10分钟.成本是书必须按照需要排列;</li>
<li>10分钟还是有点长,书生于是决定再改善,结合2和3的改进措施.书按照各种类型放在不同的架子,每个架子的书单独编号,比如文学1,文学2&hellip;.册子上也按照书种类进行分开登记.这样找一本书只需要看一个分类下的书名(100个),只需要1分钟.</li>
</ol>


<p>我们生活中的数据分为:结构化数据和非结构化数据.结构化数据指具有固定格式或有限长度的数据,如数据库或者Excel表等.非结构化数据指不定长或无固定格式的数据,如邮件,word文档等.</p>

<p>计算机的产生对信息检索产生了质的变化,帮我们做了很多简单却耗时的工作.在计算机检索的世界里面我们已知了很多技术:</p>

<pre><code>1.对链表的搜索,我们采用从头到位逐项比较,O(N)的时间复杂度;
2.对于有序数组,我们可以采用二分搜索(其实就是二叉树,通常称之为二叉查找树),能够达到O(logN),底数是2;
3.多叉数的查找比二叉树更快,参考Tire树,B树等数据结构,O(logN),底数大于2;
4.Hash表的查找理论上是O(1)的时间复杂度;
</code></pre>

<p>除了顺序查找,其他几种检索都非常的快,但是这种快都是有维护成本的,比如二分搜索需要保证数据有序,因此新来的数据的插入成本会很高,包括删除数据的成本也会很高.但是其带来的检索效率的提升是非常大的.针对结构化数据,我们往往很简单的实现数据的快速搜索,比如数据库就是使用B树来达到快速搜索的目的.</p>

<p>但是现实中99%以上的原始数据都是混乱无须的非结构化数据.当数据量很大的时候,检索成为一个极其困难的问题(量变导致质变),即使对于计算很快的计算机而言.比如一个简单的字符串查找,假设在1页书的内容(约1000字)中查找一个单词可能需要1毫秒,那么在一本书的内容中(约50W词)中查找一个名字可能需要0.5秒,在1W本书(约50亿个单词)中查找这个单词需要5000秒,也就是接近1个半小时;假设每分钟要找一次呢?不敢想象.</p>

<p>在当今网络及其发达的今天,已经很多的公司的数据量超过了1W本书的信息量.这时候无序信息的全文检索显得极其重要.因此也催生了诸如Google,Yahoo和Baidu这些搜索巨头.</p>

<p>索引是全文搜索的基础,也是现代搜索引擎的核心,建立索引的过程就是把源数据处理成非常方便查询的索引文件的过程.你可以把索引想象成这样一种数据结构,他能够使你快速的随机访问存储在索引中的关键词,进而找到该关键词所关联的文档.</p>

<p>还是以书的例子来说,假设书前三页的内容:</p>

<pre><code>//page1:
如何使用Lucene完善搜索

//page2
Lucene数据如何存储

//page3
Lucene如何实现搜索

//page4
作者:肖宝秋
</code></pre>

<p>我们首先使用分词软件见这四页的内容分词,得到以下结果:</p>

<pre><code>//page1:
如何, 使用, Lucene, 完善, 搜索

//page2
Lucene, 数据, 如何, 存储

//page3
Lucene, 如何, 实现, 搜索
作者, 肖宝秋
</code></pre>

<p>建立词&ndash;>文档的映射关系:</p>

<pre><code>如何 --&gt; page1, page2, page3
使用 --&gt; page1
Lucene --&gt; page1, page2, page3
完善 --&gt; page1
搜索 --&gt; page1, page3
数据 --&gt; page2
存储 --&gt; page2
实现 --&gt; page3
作者 --&gt; page4
肖宝秋 --&gt; page4
</code></pre>

<p>现在搜索"Lucene"的时候,我知道在page1,page2,page3中出现了.搜索"作者"的时候,我知道在page4出现了.</p>

<p>另外一个支撑现代搜索理论的既定现实是:词的数量是有限的,而且非常有限.比如常用的中文词就几万个.</p>

<h2>2.Lucene是什么</h2>

<p>简单讲,Lucene是一个高效的,基于Java的全文检索工具包,它不是一个完整的搜索应用程序,而是为你的应用程序提供索引和搜索功能.Lucene是Apache家族中的一个开源项目.也是目前最为流行的基于 Java 开源全文检索工具包.</p>

<p>Lucene 能够为文本类型的数据建立索引,所以你只要能把你要索引的数据格式转化的文本的,Lucene 就能对你的文档进行索引和搜索.比如你要对一些 HTML 文档,PDF 文档进行索引的话你只需要把 HTML 文档和 PDF 文档转化成文本格式的,然后将转化后的内容交给Lucene进行索引,然后把创建好的索引文件保存到磁盘或者内存中,最后根据用户输入的查询条件在索引文件上进行查询.不指定要索引的文档的格式也使Lucene能够几乎适用于所有的搜索应用程序.</p>

<p>下图展示搜索应用程序和Lucene之间的关系,也描述了Lucene的两个核心过程:建立索引和通过索引检索</p>

<p><img src="/images/lucene/lucene_and_application.jpg"></p>

<h4>2.1 Lucene优点</h4>

<p>Lucene作为一个全文搜索引擎,其具有如下突出的优点:</p>

<ul>
<li>1.索引文件格式独立于应用平台.Lucene定义了一套以八字节为基础的索引文件格式,使得兼容系统和不同平台的应用能够共享建立的索引文件.</li>
<li>2.在传统全文检索引擎的倒序索引的基础上实现了分块索引,能够针对新的文件建立小文件索引,提升索引速度.然后通过与原有的索引的合并,达到优化的目的.</li>
<li>3.优秀的面向对象的系统架构,使得对于Lucene扩展的学习难度降低,方便加入新功能.</li>
<li>4.设计了独立于语言和文件格式的文本分析接口,索引器通过接受token流完成索引文件的创立,用户扩展新的语言和文件格式,只需要实现文本分析的接口.</li>
<li>5.已经默认实现了一套强大的查询引擎,用户无须自己编写代码即可使系统获得强大的查询能力,Lucene的查询实现中默认实现了布尔操作、模糊查询、分组查询.</li>
</ul>


<p>参考: <a href="http://lucene.apache.org/core/index.html">http://lucene.apache.org/core/index.html</a></p>

<h4>2.2 倒排索引</h4>

<p>现代搜索引擎基本都是基于倒排索引(反向索引).因为搜索问题本质就是求解"哪文档包含搜索词"这个问题.</p>

<p>简单讲一下什么是倒排索引,简单讲就是字符串到文件的映射关系.假设我的文档集合里面有100篇文档,为了方便表示,我们为文档编号从1到100,得到下面的结构:</p>

<p><img src="/images/lucene/inverted_index.jpg"></p>

<p>左边保存的是一系列字符串,称为词典.每个字符串都指向包含此字符串的文档(Document)链表,此文档链表称为倒排表.</p>

<p>有了索引,便使保存的信息和要搜索的信息一致,可以大大加快搜索的速度.比如说,我们要寻找既包含字符串“lucene”又包含字符串“solr”的文档,我们只需要以下几步:</p>

<ol>
<li>取出包含字符串lucene的文档链表.</li>
<li>取出包含字符串solr的文档链表.</li>
<li>通过合并链表,找出既包含lucene又包含solr的文件.</li>
</ol>


<p><img src="/images/lucene/inverted_index_merge.jpg"></p>

<h2>3.Lucene建立索引</h2>

<p>Lucene的建立索引包括以下几个过程:</p>

<h4>3.1.原始文档</h4>

<p>一些要索引的原文档(Document).包括Html文档,PDF文档,MC Word文档等.而Lucene是只能处理文本文档.</p>

<p>庆幸的是现在很多工具帮我们处理这些问题.如Apache的Tika, 官网:<a href="http://tika.apache.org/">http://tika.apache.org/</a></p>

<h4>3.2.分词</h4>

<p>确定输入的文本之后首先将文本传递给分词组件,分词组件(Tokenizer)会做以下几件事情(此过程称为Tokenize):</p>

<pre><code>1. 将文档分成一个一个单独的单词;
2. 去除标点符号;
3. 去除停词(Stop word);
</code></pre>

<p>停词(Stop word)就是一种语言中最普通的一些单词,由于没有特别的意义,因而大多数情况下不能成为搜索的关键词,因而创建索引时,这种词会被去掉而减少索引的大小.英语中挺词(Stop word)如:the,a,this,is等.对于每一种语言的分词组件(Tokenizer),都有一个停词(stop word)集合.经过分词(Tokenizer)后得到的结果称为词元(Token).</p>

<h4>3.3 语言处理</h4>

<p>分词之后将词元传递给语言处理模块,语言处理组件(linguistic processor)主要是对得到的词元(Token)做一些同语言相关的处理.</p>

<p>比如对于英语,语言处理组件(Linguistic Processor)一般做以下几点:</p>

<pre><code>1. 变为小写(Lowercase).
2. 将单词缩减为词根形式,如cars到car等.这种操作称为:stemming.
3. 将单词转变为词根形式,如“drove”到“drive”等.这种操作称为:lemmatization.
</code></pre>

<p>语言处理组件(linguistic processor)的结果称为词(Term).</p>

<h4>3.4 索引</h4>

<p>语言处理之后将词给索引模块,索引模块主要做以下几个事情:</p>

<pre><code>1. 利用得到的词(Term)创建一个字典.
即Term1--&gt;doc1, Term2--&gt;doc1这种映射关系
2. 对字典按字母顺序进行排序.
3. 合并相同的词(Term)成为文档倒排链表.
</code></pre>

<p>倒排链表的格式如下:</p>

<pre><code>Term1,Document Frequency  --&gt; Doc1,Frequency1 ; Doc2,Frequency2
</code></pre>

<p>Document Frequency 即文档频次,表示总共有多少文件包含此词(Term),即链表中文档数目.
Frequency 即词频率,表示此文件中包含了几个此词(Term).</p>

<p>下面是一个建立索引的例子,输入文本如下:</p>

<pre><code>文件一:Students should be allowed to go out with their friends, but not allowed to drink beer.
文件二:My friend Jerry went to school to see his students but found them drunk which is not allowed.
</code></pre>

<p>经过分词(Tokenizer)后得到的结果称为词元(Token):</p>

<pre><code>Students,allowed,go,their,friends,allowed,drink,beer,My,friend,Jerry,went,school,see,his,students,found,them,drunk,allowed
</code></pre>

<p>经过语言处理,得到的词(Term)如下:</p>

<pre><code>student,allow,go,their,friend,allow,drink,beer,my,friend,jerry,go,school,see,his,student,find,them,drink,allow
</code></pre>

<p>最后得到的倒排索引表如下:</p>

<p><img src="/images/lucene/posting_list.jpg"></p>

<p>所以对词allow来讲,总共有两篇文档包含此词(Term),从而词(Term)后面的文档链表总共有两项,第一项表示包含allow的第一篇文档,即1号文档,此文档中,allow出现了2次,第二项表示包含allow的第二个文档,是2号文档,此文档中,allow出现了1次.</p>

<h2>4.Lucene搜索</h2>

<p>有了倒排索引,我们就可以做搜索了,但是事实上Lucene的搜索过程也不简单.</p>

<p>简单来讲,搜索解决的问题是:找到和搜索词相关性最好的文档.细分的这个问题:</p>

<pre><code>1.找到相关文档;
2.评价搜索词和文档的相关性;
</code></pre>

<p>Lucene的搜索包括以下几个过程.</p>

<h4>3.1.用户输入</h4>

<p>查询语句同我们普通的语言一样,也是有一定语法的.查询语句的语法根据全文检索系统的实现而不同.最基本的有比如:AND, OR, NOT等.举个例子,用户输入语句:lucene AND learned NOT hadoop.说明用户想找一个包含lucene和learned然而不包括hadoop的文档.</p>

<p>目前看来,Google和Baidu都不支出这种语法:</p>

<p><img src="/images/lucene/Google_Search.png"></p>

<p><img src="/images/lucene/Baidu_Search.png"></p>

<h4>3.2.词法分析,语法分析,语言处理</h4>

<p>由于查询语句有语法,因而也要进行语法分析,语法分析及语言处理.</p>

<ul>
<li><p>词法分析主要用来切词,识别单词和关键字.通常建立索引的切词组件和对搜索词的切词组件一致.</p></li>
<li><p>语法分析主要是根据查询语句的语法规则来形成一棵语法树.比如例子:lucene AND learned NOT hadoop形成的语法树如下:</p>

<p>  <img src="/images/lucene/Token_tree.jpg"></p></li>
<li><p>语言处理同索引过程中的语言处理几乎相同.如learned变成learn等.经过第三步,我们得到一棵经过语言处理的语法树.</p>

<p> <img src="/images/lucene/Term_Tree.jpg"></p></li>
</ul>


<h4>3.3 搜索索引</h4>

<p>此步骤有分几小步:</p>

<ul>
<li>在反向索引表中,分别找出包含lucene,learn,hadoop的文档链表.</li>
<li>对包含lucene,learn的链表进行合并操作,得到既包含lucene又包含learn的文档链表.</li>
<li>将此链表与hadoop的文档链表进行差操作,去除包含hadoop的文档,从而得到既包含lucene又包含learn而且不包含hadoop的文档链表.此文档链表就是我们要找的文档.</li>
</ul>


<h4>3.4 结果文档排序</h4>

<p>虽然在上一步,我们得到了想要的文档,然而对于查询结果应该按照与查询语句的相关性进行排序,越相关者越靠前.</p>

<p>通常会把查询语句看作一片短小的文档,对文档与文档之间的相关性(relevance)进行打分(scoring),分数高的相关性好,就应该排在前面.</p>

<p>对于文档之间的关系,不同的Term重要性不同,比如对于本篇文档,search, Lucene, full-text就相对重要一些,this, a , what可能相对不重要一些.所以如果两篇文档都包含search, Lucene,fulltext,这两篇文档的相关性好一些,然而就算一篇文档包含this, a, what,另一篇文档不包含this, a, what,也不能影响两篇文档的相关性.</p>

<p>找出词(Term)对文档的重要性的过程称为计算词的权重(Term weight)的过程.计算词的权重(term weight)有两个参数,第一个是词(Term),第二个是文档(Document).词的权重(Term weight)表示此词(Term)在此文档中的重要程度,越重要的词(Term)有越大的权重(Term weight),因而在计算文档之间的相关性中将发挥更大的作用.</p>

<p>下面分析这两个过程:</p>

<ul>
<li>计算权重(Term weight).</li>
</ul>


<p>影响一个词(Term)在一篇文档中的重要性主要有两个因素:</p>

<pre><code>1.Term Frequency (tf):即此Term在此文档中出现了多少次. tf越大说明越重要.
2.Document Frequency (df):即有多少文档包含次Term. df越大说明越不重要.
</code></pre>

<p>很容易理解,词(Term)在文档中出现的次数越多,说明此词(Term)对该文档越重要,如“搜索”这个词,在本文档中出现的次数很多,说明本文档主要就是讲这方面的事的.然而在一篇英语文档中,this出现的次数更多,就说明越重要吗？不是的,这是由第二个因素进行调整,第二个因素说明,有越多的文档包含此词(Term), 说明此词(Term)太普通,不足以区分这些文档,因而重要性越低.</p>

<p>简单公式如下:</p>

<p><img src="/images/lucene/Term_Weight.png"></p>

<ul>
<li>根据Term之间的关系得到文档相关性.</li>
</ul>


<p>我们把文档看作一系列词(Term),每一个词(Term)都有一个权重(Term weight),不同的词(Term)根据自己在文档中的权重来影响文档相关性的打分计算.</p>

<p>于是我们把所有此文档中词(term)的权重(term weight) 看作一个向量.</p>

<pre><code>Document = {term1, term2, …… ,term N}
Document Vector = {weight1, weight2, …… ,weight N}
</code></pre>

<p>同样我们把查询语句看作一个简单的文档,也用向量来表示.</p>

<pre><code>Query = {term1, term 2, …… , term N}
Query Vector = {weight1, weight2, …… , weight N}
</code></pre>

<p>我们把所有搜索出的文档向量及查询向量放到一个N维空间中,每个词(term)是一维:</p>

<p><img src="/images/lucene/document_relative_vsm.jpg"></p>

<p>我们认为两个向量之间的夹角越小,相关性越大.所以我们计算夹角的余弦值作为相关性的打分,夹角越小,余弦值越大,打分越高,相关性越大.</p>

<p>需要注意的是,查询语句一般是很短的,包含的词(Term)是很少的,因而查询向量的维数很小,而文档很长,包含词(Term)很多,文档向量维数很大, 但是需要放到相同的向量空间,因此要保证二者维数是相同的.处理方式很简单,维数不同时,取二者的并集,如果不含某个词(Term)时,则权重(Term Weight)为0.</p>

<p>相关性打分公式如下:</p>

<p><img src="/images/lucene/documet_relative_caculate.png"></p>

<p>举个例子,查询语句有11个Term,共有三篇文档搜索出来.其中各自的权重(Term weight),如下:</p>

<p><img src="/images/lucene/document_score.png"></p>

<p>于是计算,三篇文档同查询语句的相关性打分分别为:</p>

<p><img src="/images/lucene/score_example.png"></p>

<p>于是文档二相关性最高,先返回,其次是文档一,最后是文档三.到此为止,我们可以找到我们最想要的文档了.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[分词]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/07/17/fen-ci/"/>
    <updated>2015-07-17T01:24:30+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/07/17/fen-ci</id>
    <content type="html"><![CDATA[<p>最近有需求需要使用crate搜索时候的分词功能,正好研究一下搜索中分词相关的基础知识
.</p>

<h1>1.什么是分词</h1>

<h1>2.为什么要分词</h1>

<h1>3.怎么做分词</h1>

<p>参考：<a href="http://my.oschina.net/apdplat/blog/412921">http://my.oschina.net/apdplat/blog/412921</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Crate服务load飙高]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/07/16/cratefu-wu-loadbiao-gao/"/>
    <updated>2015-07-16T05:02:20+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/07/16/cratefu-wu-loadbiao-gao</id>
    <content type="html"><![CDATA[<p>前段时间搜索处理个P3的故障,原因是用户输入超级长的搜索字段,导致crate服务器load飙高,进而对外服务失败.</p>

<p>持续时间约10分钟.但是对我而言,最大的问题是这10分钟内,对crate服务器我什么都做不了.经过这次问题,准备好好看看crate以及背后ES的源码.</p>

<p>虽然解决方案是限制用户输入(这一点和google以及百度做法是一样的,百度的查询限制在38个汉字以内).</p>

<h1>1.like查询</h1>

<p>有问题的字段是name字段,使用crate的简单的like查询.根据官方文档,crate的like查询支持两种通配符:</p>

<pre><code>% : 0个或者多个字符
_ : 单个字符
</code></pre>

<p>需要注意的注意,使用like查询可能导致慢查询.特别是当使用前置通配符开头的like查询.因为这种情况下crate需要去迭代所有行,而不能使用索引.
如果向获取更好的性能,可以考虑使用全文索引.</p>

<p>like参考:<a href="https://crate.io/docs/en/latest/sql/queries.html#like">https://crate.io/docs/en/latest/sql/queries.html#like</a></p>

<p>全文索引参考: <a href="https://crate.io/docs/en/latest/sql/fulltext.html">https://crate.io/docs/en/latest/sql/fulltext.html</a> <a href="https://crate.io/docs/en/latest/sql/ddl.html#fulltext-indices">https://crate.io/docs/en/latest/sql/ddl.html#fulltext-indices</a></p>

<h1>2.crate符取异常日志</h1>

<p>这里贴一下当时crate服务器的异常:
<code>
org.elasticsearch.index.query.QueryParsingException: [merchant_sea] Failed to parse
        at org.elasticsearch.index.query.IndexQueryParserService.parseQuery(IndexQueryParserService.java:370)
        at org.elasticsearch.action.count.TransportCountAction.shardOperation(TransportCountAction.java:187)
        at org.elasticsearch.action.count.CrateTransportCountAction.shardOperation(CrateTransportCountAction.java:119)
        at org.elasticsearch.action.count.CrateTransportCountAction.shardOperation(CrateTransportCountAction.java:49)
        at org.elasticsearch.action.support.broadcast.TransportBroadcastOperationAction$AsyncBroadcastAction$1.run(TransportBroadcastOperationAction.java:171)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
        at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.lucene.util.automaton.TooComplexToDeterminizeException: Determinizing automaton would result in more than 10000 states.
        at org.apache.lucene.util.automaton.Operations.determinize(Operations.java:743)
        at org.apache.lucene.util.automaton.RunAutomaton.&lt;init&gt;(RunAutomaton.java:138)
        at org.apache.lucene.util.automaton.ByteRunAutomaton.&lt;init&gt;(ByteRunAutomaton.java:32)
        at org.apache.lucene.util.automaton.CompiledAutomaton.&lt;init&gt;(CompiledAutomaton.java:203)
        at org.apache.lucene.search.AutomatonQuery.&lt;init&gt;(AutomatonQuery.java:84)
        at org.apache.lucene.search.AutomatonQuery.&lt;init&gt;(AutomatonQuery.java:65)
        at org.apache.lucene.search.WildcardQuery.&lt;init&gt;(WildcardQuery.java:57)
        at org.elasticsearch.index.query.WildcardQueryParser.parse(WildcardQueryParser.java:106)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.BoolQueryParser.parse(BoolQueryParser.java:93)
        at org.elasticsearch.index.query.QueryParseContext.parseInnerQuery(QueryParseContext.java:281)
        at org.elasticsearch.index.query.IndexQueryParserService.innerParse(IndexQueryParserService.java:382)
        at org.elasticsearch.index.query.IndexQueryParserService.parse(IndexQueryParserService.java:281)
        at org.elasticsearch.index.query.IndexQueryParserService.parse(IndexQueryParserService.java:276)
        at org.elasticsearch.index.query.IndexQueryParserService.parseQuery(IndexQueryParserService.java:354)
        ... 7 more
</code></p>

<h1>3.背后的原理</h1>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch配置解析]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/05/21/elasticsearchpei-zhi-jie-xi/"/>
    <updated>2015-05-21T04:31:05+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/05/21/elasticsearchpei-zhi-jie-xi</id>
    <content type="html"><![CDATA[<p>可以使用正则grep出各个配置项:
<code>
grep '^#\w' elasticsearch.yml
</code></p>

<p>解析Elasticsearch的配置文件elasticsearch.yml中各个关键参数的意义:</p>

<pre><code>################################### Cluster ###################################
elasticsearch的config文件夹里面有两个配置文件：elasticsearch.yml和logging.yml，第一个是es的基本配置文件，第二个是日志配置文件，es也是使用log4j来记录日志的，所以logging.yml里的设置按普通log4j配置文件来设置就行了。下面主要讲解下elasticsearch.yml这个文件中可配置的东西。

cluster.name: elasticsearch
配置es的集群名称，默认是elasticsearch，es会自动发现在同一网段下的es，如果在同一网段下有多个集群，就可以用这个属性来区分不同的集群。

node.name: "Franz Kafka"
节点名，默认随机指定一个name列表中名字，该列表在es的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字。

node.master: true
指定该节点是否有资格被选举成为node，默认是true，es是默认集群中的第一台机器为master，如果这台机挂了就会重新选举master。

node.data: true
指定该节点是否存储索引数据，默认为true。

index.number_of_shards: 5
设置默认索引分片个数，默认为5片。

index.number_of_replicas: 1
设置默认索引副本个数，默认为1个副本。

path.conf: /path/to/conf
设置配置文件的存储路径，默认是es根目录下的config文件夹。

path.data: /path/to/data
设置索引数据的存储路径，默认是es根目录下的data文件夹，可以设置多个存储路径，用逗号隔开，例：
path.data: /path/to/data1,/path/to/data2

path.work: /path/to/work
设置临时文件的存储路径，默认是es根目录下的work文件夹。

path.logs: /path/to/logs
设置日志文件的存储路径，默认是es根目录下的logs文件夹

path.plugins: /path/to/plugins
设置插件的存放路径，默认是es根目录下的plugins文件夹

bootstrap.mlockall: true
设置为true来锁住内存。因为当jvm开始swapping时es的效率会降低，所以要保证它不swap，可以把ES_MIN_MEM和ES_MAX_MEM两个环境变量设置成同一个值，并且保证机器有足够的内存分配给es。同时也要允许elasticsearch的进程可以锁住内存，linux下可以通过`ulimit -l unlimited`命令。设置ES_HEAP_SIZE表示ES_MIN_MEM和ES_MAX_MEM相同且为ES_HEAP_SIZE的值.

network.bind_host: 192.168.0.1
设置绑定的ip地址，可以是ipv4或ipv6的，默认为0.0.0.0。

network.publish_host: 192.168.0.1
设置其它节点和该节点交互的ip地址，如果不设置它会自动判断，值必须是个真实的ip地址。

network.host: 192.168.0.1
这个参数是用来同时设置bind_host和publish_host上面两个参数。

transport.tcp.port: 9300
设置节点间交互的tcp端口，默认是9300。

transport.tcp.compress: true
设置是否压缩tcp传输时的数据，默认为false，不压缩。

http.port: 9200
设置对外服务的http端口，默认为9200。

http.max_content_length: 100mb
设置内容的最大容量，默认100mb

http.enabled: false
是否使用http协议对外提供服务，默认为true，开启。

gateway.type: local
gateway的类型，默认为local即为本地文件系统，可以设置为本地文件系统，分布式文件系统，hadoop的HDFS，和amazon的s3服务器，其它文件系统的设置方法下次再详细说。

gateway.recover_after_nodes: 1
设置集群中N个节点启动时进行数据恢复，默认为1。

gateway.recover_after_time: 5m
设置初始化数据恢复进程的超时时间，默认是5分钟。

gateway.expected_nodes: 2
设置这个集群中节点的数量，默认为2.一旦一旦这N个节点启动(并且数字和recover_after_nodes相同),就会立即开始数据恢复而不用等待gateway.recover_after_time时间之后再开始.

cluster.routing.allocation.node_initial_primaries_recoveries: 4
初始化数据恢复时，并发恢复线程的个数，默认为4。

cluster.routing.allocation.node_concurrent_recoveries: 2
添加删除节点或负载均衡时并发恢复线程的个数，默认为4。

indices.recovery.max_size_per_sec: 0
设置数据恢复时限制的带宽，如入100mb，默认为0，即无限制。

indices.recovery.concurrent_streams: 5
设置这个参数来限制从其它分片恢复数据时最大同时打开并发流的个数，默认为5。

discovery.zen.minimum_master_nodes: 1
设置这个参数来保证集群中的节点可以知道其它N个有master资格的节点。默认为1，对于大的集群来说，可以设置大一点的值(2-4).

discovery.zen.ping.timeout: 3s
设置集群中自动发现其它节点时ping连接超时时间，默认为3秒，对于比较差的网络环境可以高点的值来防止自动发现时出错。

discovery.zen.ping.multicast.enabled: false
设置是否打开多播发现节点，默认是true。使用单播发现节点策略(Unicast discovery)允许显示的控制使用哪个节点去发现集群.

discovery.zen.ping.unicast.hosts: ["host1", "host2:port", "host3[portX-portY]"]
设置集群中master节点的初始列表，可以通过这些节点来自动发现新加入集群的节点。

下面是一些查询时的慢日志参数设置,默认日志级别为TRACE.
超过10秒的查询打印warn日志,超过5秒的查询打印info日志,超过2秒的查询打印debug日志,超过0.5秒的查询打印trace日志
index.search.slowlog.level: TRACE
index.search.slowlog.threshold.query.warn: 10s
index.search.slowlog.threshold.query.info: 5s
index.search.slowlog.threshold.query.debug: 2s
index.search.slowlog.threshold.query.trace: 500ms

index.search.slowlog.threshold.fetch.warn: 1s
index.search.slowlog.threshold.fetch.info: 800ms
index.search.slowlog.threshold.fetch.debug:500ms
index.search.slowlog.threshold.fetch.trace: 200ms

超过10秒的查检索引打印warn日志,超过5秒的查检索引打印info日志,超过2秒的查检索引打印debug日志,超过0.5秒的查检索引打印trace日志
index.indexing.slowlog.threshold.index.warn: 10s
index.indexing.slowlog.threshold.index.info: 5s
index.indexing.slowlog.threshold.index.debug: 2s
index.indexing.slowlog.threshold.index.trace: 500ms

下面是GC日志相关的配置,young GC超过1000ms打印warn日志,超过700ms打印info日志,超过400ms打印的debug日志
monitor.jvm.gc.young.warn: 1000ms
monitor.jvm.gc.young.info: 700ms
monitor.jvm.gc.young.debug: 400ms

full GC超过10s打印warn日志,超过5s打印info日志,超过2s打印的debug日志
monitor.jvm.gc.old.warn: 10s
monitor.jvm.gc.old.info: 5s
monitor.jvm.gc.old.debug: 2s
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Elasticsearch]]></title>
    <link href="http://xiaobaoqiu.github.io/blog/2015/05/20/elasticsearch/"/>
    <updated>2015-05-20T22:14:33+08:00</updated>
    <id>http://xiaobaoqiu.github.io/blog/2015/05/20/elasticsearch</id>
    <content type="html"><![CDATA[<h1>1.简介</h1>

<p>Elasticsearch 是一个建立在全文搜索引擎 Apache Lucene&trade; 基础上的分布式的，高可用的，基于json格式的数据构建索引，准实时查询的搜索引擎。Lucene 是当今最先进最高效的全功能开源搜索引擎框架,但是Lucene使用非常复杂。</p>

<p>Elasticsearch使用 Lucene 作为内部引擎，但是在你使用它做全文搜索时，只需要使用统一开发好的API即可，而并不需要了解其背后复杂的 Lucene 的运行原理。</p>

<p>Elasticsearch是一种准实时搜索，其实是可以做到实时的，因为lucene是可以做到实时的，但是这样做，要么是牺牲索引的效率（每次都索引之后刷新），要么就是牺牲查询的效率（每次查询之前都进行刷新），所以
采取一种折中的方案，每隔n秒自动刷新，这样你创建索引之后，最多在ns之内肯定能查到，这就是所谓的准实时(near real-time)查询，缺省是刷新间隔时间是1秒，可以通过index.refresh_interval参数修改间隔.</p>

<p>刷新是为了让文档可以搜索到，但是不保证这些数据被写入disk进入一个永久的存储状态，数据会被先被写入一个事务日志，然后在适当的时候持久化到磁盘中.</p>

<p>官网:<a href="https://www.elastic.co/products/elasticsearch">https://www.elastic.co/products/elasticsearch</a></p>

<p>文档:<a href="https://www.elastic.co/guide/index.html">https://www.elastic.co/guide/index.html</a></p>

<p>github地址:<a href="https://github.com/elastic/elasticsearch">https://github.com/elastic/elasticsearch</a></p>

<p>博客地址:<a href="https://www.elastic.co/blog">https://www.elastic.co/blog</a></p>

<p>其优点很吸引人:</p>

<pre><code>1.分布式,可扩展,高科用(Distributed, scalable, and highly available);
2.提供实时搜索和分析(Real-time search and analytics capabilities);
3.复杂的RESTful API接口(Sophisticated RESTful API);
</code></pre>

<p>其特征如下:</p>

<pre><code>1.Real-Time Data
2.Real-Time Analytics
3.Distributed
最开始规模可能很小,elasticsearch很方便的支持横向扩展,通过简单的在集群中增加节点就可以
4.High Availability
Elasticsearch集群是弹性的,它可以自动的感知新增的或者失效的节点,自动做数据的分发和均衡,保证数据客房问并且是安全的.
5.Multitenancy
集群可能包含多个索引(index),它们可以独立的提供查询服务,也可以组合在一起对外提供查询服务.
6.Full-Text Search
支持多种开发语言
7.Document-Oriented
将真实世界的复杂对象结构化乘JSON文档.所有字段默认都建立索引,所有的索引都可以单独提供查询.并且瞬间(breathtaking speed)返回复杂结果.
8.Schema-Free
对一个JSON文档建立索引,就会自动识别数据的结构和类型,创建所有并对外提供搜索服务.同时也可以自定义数据如何建立索引.
9.Developer-Friendly, RESTful API
Elasticsearch是API驱动的.基本所有的操作都可以通过一个简单的使用JSON格式数据的HTTP上的RESTful API.提供了很多种语言的Client.
10.Per-Operation Persistence
Elasticsearch将数据安全放在第一位.任何文档的变更都会记录在集群中多个节点上的事物日志,以此来将数据丢失几率降低到最小.
11.Apache 2 Open Source License
12.Build on top of Apache Lucene
Elasticsearch以Lucene为基础提供其优秀的分布式搜索和分析能力.
13.Conflict Management
</code></pre>

<h1>2.安装</h1>

<h3>2.1 elasticsearch安装</h3>

<p>安装很简单:</p>

<pre><code>1.下载并解压
下载地址:https://www.elastic.co/downloads/elasticsearch
这里下载是1.5.2版本,解压之后可以创建软链es:

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>xiaobaoqiu@xiaobaoqiu:~/elasticsearch$ ln -s elasticsearch-1.5.2 es</span></code></pre></td></tr></table></div></figure>

目录下主要三个文件夹:

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>xiaobaoqiu@xiaobaoqiu:~/elasticsearch/es$ ll
</span><span class='line'>总用量 48
</span><span class='line'>drwxr-xr-x 5 xiaobaoqiu xiaobaoqiu  4096  4月 27 09:22 ./
</span><span class='line'>drwxr-xr-x 3 xiaobaoqiu xiaobaoqiu  4096  5月 20 14:40 ../
</span><span class='line'>drwxr-xr-x 2 xiaobaoqiu xiaobaoqiu  4096  4月 27 09:22 bin/
</span><span class='line'>drwxr-xr-x 2 xiaobaoqiu xiaobaoqiu  4096  5月 20 14:42 config/
</span><span class='line'>drwxr-xr-x 3 xiaobaoqiu xiaobaoqiu  4096  4月 27 09:22 lib/
</span><span class='line'>-rw-rw-r-- 1 xiaobaoqiu xiaobaoqiu 11358  4月 27 07:05 LICENSE.txt
</span><span class='line'>-rw-rw-r-- 1 xiaobaoqiu xiaobaoqiu   150  4月 27 07:05 NOTICE.txt
</span><span class='line'>-rw-rw-r-- 1 xiaobaoqiu xiaobaoqiu  8499  4月 27 09:03 README.textile</span></code></pre></td></tr></table></div></figure>
其中bin包含一些启动脚本(包括windows下的bat脚本和linux下的shell脚本),config主要是配置文件,lib包括es依赖的jar,在里面就可以看到熟悉的Lucene,查询,高亮等依赖的jar包.

启动elasticsearch之后会产生log目录,用于记录elasticsearch系统的一些中心日志信息:

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>-rw-r--r-- 1    0  5月 20 15:05 elasticsearch_index_indexing_slowlog.log
</span><span class='line'>-rw-r--r-- 1    0  5月 20 15:05 elasticsearch_index_search_slowlog.log
</span><span class='line'>-rw-r--r-- 1 1254  5月 20 15:06 elasticsearch.log</span></code></pre></td></tr></table></div></figure>
其中elasticsearch.log是系统日志,记录什么类型的日志,日志的命名及日志文件的滚动(Rolling)策略等由config目录下的logging.yml配置文件决定.

启动elasticsearch之后会产生data目录,用于
elasticSearch的数据存放位置

2.启动
直接启动bin目录下的elasticsearch的shell:

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>xiaobaoqiu@xiaobaoqiu:~/elasticsearch/es/bin$ ./elasticsearch -d</span></code></pre></td></tr></table></div></figure>

3.验证
直接本机浏览器访问:http://localhost:9200/

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>{
</span><span class='line'>status: 200,
</span><span class='line'>name: "Agon",
</span><span class='line'>cluster_name: "elasticsearch",
</span><span class='line'>version: {
</span><span class='line'>    number: "1.5.2",
</span><span class='line'>    build_hash: "62ff9868b4c8a0c45860bebb259e21980778ab1c",
</span><span class='line'>    build_timestamp: "2015-04-27T09:21:06Z",
</span><span class='line'>    build_snapshot: false,
</span><span class='line'>    lucene_version: "4.10.4"
</span><span class='line'>},
</span><span class='line'>tagline: "You Know, for Search"
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>
这说明Elasticsearch集群已经上线运行了，这时我们就可以进行各种实验了.
</code></pre>

<h3>2.2 集群管理工具插件</h3>

<p>elasticsearch-head是一个elasticsearch的集群管理工具，它是完全由html5编写的独立网页程序，其他它可以更好的获得各个切片和节点的信息.</p>

<p>该工具的git地址是： <a href="https://github.com/Aconex/elasticsearch-head">https://github.com/Aconex/elasticsearch-head</a></p>

<p>安装该插件:</p>

<pre><code>xiaobaoqiu@xiaobaoqiu:~/elasticsearch$ ./es/bin/plugin -install mobz/elasticsearch-head
-&gt; Installing mobz/elasticsearch-head...
...//省略若干
</code></pre>

<p>然后就可以访问(可以使用具体节点的IP):
<a href="http://localhost:9200/_plugin/head/">http://localhost:9200/_plugin/head/</a></p>

<p>图形化界面如下,包括集群的健康状况等信息:</p>

<p><img src="/images/Elasticsearch/elasticsearch_plugin_head.png"></p>

<h3>2.3 集群监控工具插件</h3>

<p>bigdesk是elasticsearch的一个集群监控工具，可以通过它来查看es集群的各种状态，如：cpu、内存使用情况，索引数据、搜索情况，http连接数等。</p>

<p>项目git地址： <a href="https://github.com/lukas-vlcek/bigdesk">https://github.com/lukas-vlcek/bigdesk</a></p>

<p>安装该插件:</p>

<pre><code>xiaobaoqiu@xiaobaoqiu:~/elasticsearch$ ./es/bin/plugin -install lukas-vlcek/bigdesk
-&gt; Installing lukas-vlcek/bigdesk...
...//省略若干
</code></pre>

<p>然后就可以访问(可以使用具体节点的IP):
<a href="http://localhost:9200/_plugin/bigdesk/">http://localhost:9200/_plugin/bigdesk/</a></p>

<p>图形化界面如下,包括JVM,Thread Pools,OS,Process,HTTP &amp; Transport,Indices和File system等监控图:</p>

<p><img src="/images/Elasticsearch/elasticsearch_plugin_bigdesk.png"></p>

<h3>2.4 安装Marvel</h3>

<p>Marvel是Elasticsearch的管理和监控工具，是一个商业版本的插件,在开发环境下免费使用。它包含了一个叫做Sense的交互式控制台，使用户方便的通过浏览器直接与Elasticsearch进行交互。</p>

<p>运行以下命令来下载和安装Marvel:</p>

<pre><code>xiaobaoqiu@xiaobaoqiu:~/elasticsearch$ ./es/bin/plugin -i elasticsearch/marvel/latest
-&gt; Installing elasticsearch/marvel/latest...
...//省略若干
</code></pre>

<p>Marvel包括一系列酷炫的监控,还有一个Sense的交互式控制台:</p>

<p><img src="/images/Elasticsearch/elasticsearch_plugin_marvel.png"></p>

<p><img src="/images/Elasticsearch/elasticsearch_plugin_marvel_sense.png"></p>

<p>你可能想要禁用监控，你可以通过以下命令关闭Marvel：</p>

<pre><code>echo 'marvel.agent.enabled: false' &gt;&gt; ./config/elasticsearch.yml
</code></pre>

<h1>3.基本概念</h1>

<h3>3.1 集群和节点</h3>

<p>节点是Elasticsearch运行的实例。集群是一组有着同样cluster.name的节点，它们协同工作，互相分享数据，提供了故障转移和扩展的功能。当然一个节点也可以是一个集群。ES集群有自动发现的机制，只要几个节点用的是一个clustername，并且在一个局域网内，那么这些节点就可以自动的发现对方，并组成一个集群.</p>

<p>我们上面的运行就是一个单节点的集群.节点的cluster.name在配置文件elasticsearch.yml中配置,默认就叫elasticsearch:</p>

<pre><code>cluster.name: elasticsearch
</code></pre>

<p>ES的集群是一个去中心化的集群，每一个节点都可以被选举为主节点，如果主节点挂了，集群就会选举出新的主节点。</p>

<p>主节点的作用主要是管理集群，例如感知集群节点的增加和减少，平衡数据分配等.</p>

<p>ES集群对外是透明的，各个节点之间协同工作，分享数据，我们不管访问的是哪一个节点，这个节点都知道数据存在于哪个节点上，然后转发请求到数据所在的节点上，并且负责收集各节点返回的数据，最后一起返回给客户端.</p>

<h3>3.2 分片(shard)</h3>

<p>一个索引会被分割为多个片段存储，这样可以充分使用节点的吞吐率</p>

<h3>3.2 索引(index)</h3>

<p>相当于数据库</p>

<h3>3.3 类型(type)</h3>

<p>相当于数据库中的表</p>

<h3>3.4 文档(doc)</h3>

<p>相当于数据库中的一条记录，json串</p>

<h3>3.5 字段(Field)</h3>

<p>相当路数据库中的列。</p>

<p>参考:
<a href="http://es.xiaoleilu.com/">http://es.xiaoleilu.com/</a></p>
]]></content>
  </entry>
  
</feed>
